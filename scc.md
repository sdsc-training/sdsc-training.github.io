# HPC Students - Student Cluster Competition (SCC)

One of the largest technical meetings in HPC in the world is the annual Supercomputing Conference (https://supercomputing.org ). SC supports many student activities, including the Student Cluster Competition (http://www.studentclustercompetition.us/. SCC was developed in 2007 to immerse undergraduate and high school students in high performance computing.  Student teams must learn to design and build small clusters  with support form hardware and software vendor partners, learn designated scientific applications, apply optimization techniques for their chosen architectures. At the SC conference, teams of 6 students compete against teams from all over the world, in a non-stop, 48-hour challenge to complete a real-world scientific workload, keep the cluster up and running on their own( without help from mentors/teachers), attending conference events, and demonstrating to the judges their HPC knowledge and skills. Acceptance to the SC competition is competitive and requires intense preparation and skill development. 

This year, SDSC is excited to announce that HPC Students will begin training UCSD students to participate in its Student Cluster Competition Program (and other potential HPC activities). Our goal is to successfully apply to be a team at the SCCâ€™19 competition, to be held in Denver this Fall. However, this will be an annual activity, with future opportunities including sponsoring a team for the ISC High Performance comptuing meeting during Summer 2020 (https://www.isc-hpc.com/). For 2019, our training activities will include the following: (1)  HPC training during the Spring quarter; (2) HPC Cluster Buildout - a Summer of fun working on a state-of-the-art HPC Cluster; and (3) selection and development of the SCC team who will travel to SC. 

Although participation on the team is limited to undergraduates, registration is open to UCSD undegraduate and graduate students. Register here:  <a href="https://www.eiseverywhere.com/2019-scctraining">SCC Registration</a> 

## (1) HPC training: 
We have planned a series of 10 training sessions, to be held on Fridays from 1:00pm to 3:00pm in the SDSC Auditorium. The scope of the training effort includes several skill development activities, including:
* Study HPC architectures, software, and admin skills.
* Learn the basics of parallel programming, including MPI using C, Fortran, and possibly other languages.
* Running HPC applications in the areas of performance characterization of the cluster, bioinformatics, numerical methods, password security, and other applications.
* Visualization and analysis of big data sets.
* Work as a team to develop and work on the items above
Students who successfully complete the HPC Training program will receive an SDSC Certificate of Completion in HPC Training, and will become eligible to apply to be on the SCC Core team. Note: the final SCC team who will travel to the competition will be chosen from this group.

## (2) Summer HPC Cluster Buildout:  
Once the training sessions have been completed, a group of the top students (appx 20) who have completed the program will be selected to work on the SCC core team. The team will work throughout the Summer to build out and admin an HPC cluster (on loan to SDSC for the competition) and start training on the science applications

## (3) SCC Team Finalization: 
The final 6 (plus alternates), who will travel to the meeting, will be chosen from the SCC core group. All team members will be participating in preparing for the actual meeting.

<h2>SCC Training Plan (Tentative):</h2>
<table style="width 90%;" >
   <tr>
      <th>WEEK</th>
      <th>DATES</th>
      <th>TOPIC</th> 
      <th>DETAILS</th>
   </tr>
   <tr>
      <th>0</th>
      <th>4/1/19</th> 
      <th>Spring quarter</th>
      <th>Quarter begins</th>
  </tr>
  <tr>
      <th>1</th>
      <th>4/5/19</th> 
      <th>SCC Program/th>
      <th>SCC History & SDSC Plan ; Registration process & accounts;SCC Apps Overview (Linpack; HPCG; mystery; hopefully have list by then);Data center tour at end</th>
  </tr>
  <tr>
      <th>1</th>
      <th>4/5/19</th> 
      <th>HPC Overview</th>
      <th>Overview of HPC history;Architecture: systems, networks,; data, ...</th>
  </tr>
   <tr>
      <th>2</th>
      <th>4/12/19</th> 
      <th>Basic Unix Skills</th>
      <th>Linux intro; basic unix tools ssh, scp</th>
  </tr>  
   <tr>
      <th>3</th>
      <th>4/19/19</th> 
      <th>Intro to Running Jobs on Comet</th>
      <th><ul>
         <li>Comet Architecture</li>
         <li>Hands-on examples</li>
         <li>System software Running jobs</li>
         <li>Queues & batch; files IO</li>
         </ul>
      </th>
  </tr>  
   <tr>
      <th>4</th>
      <th>4/26/19</th> 
      <th>Threads</th>
      <th>Pthreads, OpenMPI</th>
  </tr>  
   <tr>
      <th>5</th>
      <th>5/3/19</th> 
      <th>MPI, part 1</th>
      <th>Intro to MPI; Comms/network; prof w/timers</th>
  </tr>  
   <tr>
      <th>6</th>
      <th>5/10/19</th> 
      <th>MPI, part 2</th>
      <th>File IO; other topics tbd</th>
  </tr>  
   <tr>
      <th>7</th>
      <th>5/17/19</th> 
      <th>GPU/CUDA</th>
      <th>Architecture: CUDA; IO; prof w/timers</th>
  </tr>  
   <tr>
      <th>8</th>
      <th>5/24/19</th> 
      <th>Performance, Optimization, and Profiling</th>
      <th>Bobs talk/webinar(?) Common profiling and monitoring software and tools Gprof ARM MAP</th>
  </tr>  
   <tr>
       <th>9</th>
      <th>5/31/19</th> 
      <th>Data Analytics</th>
      <th>Tensor flow; torch; horovod (mach learning)</th>
  </tr> 
   <tr>
      <th>10</th>
      <th>6/7/19</th> 
      <th>Optional Topics</th>
      <th>SCC Core group Selection completed before finals</th>
  </tr>  
   <tr>
      <th>11</th>
      <th>6/8/19 - 6/14/19</th> 
      <th>Q3-Spring ends</th>
      <th>Final exams week</th>
  </tr>  
  </table>
  
  
